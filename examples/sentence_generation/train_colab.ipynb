{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generation-train-colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p36hSZiX6RNF"
      },
      "source": [
        "# 패키지 설치하기\n",
        "\n",
        "TPU 관련 패키지를 설치합니다. TPU 사용시 아래 라인 첫 문자(#)를 지우고 수행하세요. GPU를 쓴다면 아래 라인을 실행할 필요가 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRTSTtBFO8jo"
      },
      "source": [
        "# TPU 사용시 아래 라인 첫 문자(#)를 지우고 수행하세요.\n",
        "#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YixrCxo8O8N_"
      },
      "source": [
        "TPU 이외에 의존성 있는 패키지를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U3MeuPe4HkP"
      },
      "source": [
        "!pip install ratsnlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skjaa0Gk6d_X"
      },
      "source": [
        "# 구글 드라이브 연동하기\n",
        "모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCGKzLXJuED"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML-ubp246uzI"
      },
      "source": [
        "# 각종 설정\n",
        "모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtoPBSH4v31j"
      },
      "source": [
        "import torch\n",
        "from ratsnlp.nlpbook.generation import GenerationTrainArguments\n",
        "args = GenerationTrainArguments(\n",
        "    pretrained_model_name=\"skt/kogpt2-base-v2\",\n",
        "    downstream_corpus_name=\"nsmc\",\n",
        "    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-generation\",\n",
        "    max_seq_length=32,\n",
        "    batch_size=32 if torch.cuda.is_available() else 4,\n",
        "    learning_rate=5e-5,\n",
        "    epochs=3,\n",
        "    tpu_cores=0 if torch.cuda.is_available() else 8,\n",
        "    seed=7,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48RjaTAr7D4M"
      },
      "source": [
        "# 랜덤 시드 고정\n",
        "학습 재현을 위해 랜덤 시드를 고정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuacSUSd7JRf"
      },
      "source": [
        "from ratsnlp import nlpbook\n",
        "nlpbook.set_seed(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeTvf0bc9bbV"
      },
      "source": [
        "# 로거 설정\n",
        "메세지 출력 등을 위한 logger를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "251gdehZ9iPZ"
      },
      "source": [
        "nlpbook.set_logger(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqUazvWL7Pry"
      },
      "source": [
        "# 말뭉치 다운로드\n",
        "실습에 사용할 말뭉치(NSMC)를 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyaJgPA7Zxi"
      },
      "source": [
        "from Korpora import Korpora\n",
        "Korpora.fetch(\n",
        "    corpus_name=args.downstream_corpus_name,\n",
        "    root_dir=args.downstream_corpus_root_dir,\n",
        "    force_download=args.force_download,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DnwLCKB7cRq"
      },
      "source": [
        "# 토크나이저 준비\n",
        "토큰화를 수행하는 토크나이저를 선언합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlcoBivi7hIY"
      },
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    eos_token=\"</s>\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbLCM5e7i6g"
      },
      "source": [
        "# 학습데이터 구축\n",
        "학습데이터를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9s8znA17ovP"
      },
      "source": [
        "from ratsnlp.nlpbook.generation import NsmcCorpus, GenerationDataset\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
        "corpus = NsmcCorpus()\n",
        "train_dataset = GenerationDataset(\n",
        "    args=args,\n",
        "    corpus=corpus,\n",
        "    tokenizer=tokenizer,\n",
        "    mode=\"train\",\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=RandomSampler(train_dataset, replacement=False),\n",
        "    collate_fn=nlpbook.data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOAACuBY7vem"
      },
      "source": [
        "# 테스트 데이터 구축\n",
        "학습 중에 평가할 테스트 데이터를 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcm1tgfq7y84"
      },
      "source": [
        "val_dataset = GenerationDataset(\n",
        "    args=args,\n",
        "    corpus=corpus,\n",
        "    tokenizer=tokenizer,\n",
        "    mode=\"test\",\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=SequentialSampler(val_dataset),\n",
        "    collate_fn=nlpbook.data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HztMCywb70e9"
      },
      "source": [
        "# 모델 초기화\n",
        "프리트레인이 완료된 GPT2 모델을 읽고, 문장 생성 모델을 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "staYwMx88MWQ"
      },
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "model = GPT2LMHeadModel.from_pretrained(\n",
        "    args.pretrained_model_name\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYtJXijM8PN8"
      },
      "source": [
        "# 학습 준비\n",
        "Task와 Trainer를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FFn4MSz8SWu"
      },
      "source": [
        "from ratsnlp.nlpbook.generation import GenerationTask\n",
        "task = GenerationTask(model, args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18W4vRtR8UTx"
      },
      "source": [
        "trainer = nlpbook.get_trainer(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KteHdhBT8X0e"
      },
      "source": [
        "# 학습\n",
        "준비한 데이터와 모델로 학습을 시작합니다. 학습 결과물(체크포인트)은 미리 연동해둔 구글 드라이브의 준비된 위치(`/gdrive/My Drive/nlpbook/checkpoint-generation`)에 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDr3M_nF8l7M"
      },
      "source": [
        "trainer.fit(\n",
        "    task,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=val_dataloader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}